# EDSR for Histopathology Super-Resolution

[![Python 3.9](https://img.shields.io/badge/python-3.9-blue.svg)](https://www.python.org/downloads/release/python-390/)
[![PyTorch 1.13](https://img.shields.io/badge/PyTorch-1.13-red.svg)](https://pytorch.org/)
[![BasicSR](https://img.shields.io/badge/BasicSR-framework-green.svg)](https://github.com/XPixelGroup/BasicSR)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

Una implementaciÃ³n especializada de **Enhanced Deep Super-Resolution Network (EDSR)** optimizada para imÃ¡genes de histopatologÃ­a de cÃ¡ncer de mama. Este proyecto forma parte de un **Trabajo de Grado** enfocado en super-resoluciÃ³n para aplicaciones mÃ©dicas mediante arquitecturas CNN residuales.

## ğŸ¯ **Objetivo del Proyecto**

Adaptar y evaluar EDSR, una arquitectura CNN residual consolidada y estable, para super-resoluciÃ³n de imÃ¡genes de microscopia histopatolÃ³gica, aprovechando su simplicidad arquitectural y robustez en el entrenamiento.

## âœ¨ **CaracterÃ­sticas Principales**

- **ğŸ”¬ Especializado en HistopatologÃ­a**: Optimizado para imÃ¡genes de cÃ¡ncer de mama
- **ğŸ—ï¸ Arquitectura CNN Residual**: Utiliza bloques residuales profundos para mejor reconstrucciÃ³n
- **âš¡ Estabilidad Excepcional**: Entrenamiento robusto sin mode collapse o inestabilidades
- **ğŸ¯ Simplicidad Efectiva**: Arquitectura limpia y bien documentada
- **ğŸ“Š Referencia Confiable**: Excelente baseline para comparaciones experimentales
- **ğŸ“ˆ Sistema de EvaluaciÃ³n Comprehensive**: MÃ©tricas especializadas para imÃ¡genes mÃ©dicas

## ğŸ”„ **Diferencias con el Proyecto Original**

Este repositorio estÃ¡ basado en [BasicSR](https://github.com/XPixelGroup/BasicSR) pero incluye adaptaciones especÃ­ficas:

| Aspecto | BasicSR Original | Esta ImplementaciÃ³n |
|---------|------------------|-------------------|
| **Dominio** | ImÃ¡genes naturales (DIV2K) | HistopatologÃ­a especÃ­fica |
| **Dataset** | Datasets estÃ¡ndar | Dataset histopatolÃ³gico especializado |
| **ConfiguraciÃ³n** | Configuraciones generales | Optimizadas para imÃ¡genes mÃ©dicas |
| **EvaluaciÃ³n** | MÃ©tricas bÃ¡sicas | Sistema comprehensive mÃ©dico |
| **Entrenamiento** | Multi-escala estÃ¡ndar | Enfoque en factores especÃ­ficos |
| **AplicaciÃ³n** | Uso general | DiagnÃ³stico mÃ©dico asistido |

## ğŸš€ **Inicio RÃ¡pido**

### Prerequisitos
- Python 3.9+
- PyTorch 1.13+
- CUDA 11.2+ (recomendado)
- GPU con 8GB+ VRAM para entrenamiento

### 1. Clonar el Repositorio
```bash
git clone https://github.com/JuanHoKKeR/EDSR_BasicSR.git
cd EDSR_BasicSR
```

### 2. InstalaciÃ³n de Dependencias
```bash
# Instalar BasicSR y dependencias
pip install basicsr
pip install -r requirements.txt

# Instalar en modo desarrollo (recomendado)
python setup.py develop
```

### 3. Preparar el Dataset
Organiza tu dataset con la siguiente estructura:
```
datasets/
â”œâ”€â”€ histopatologia/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ hr/              # ImÃ¡genes de alta resoluciÃ³n
â”‚   â”‚   â””â”€â”€ lr/              # ImÃ¡genes de baja resoluciÃ³n
â”‚   â”œâ”€â”€ val/
â”‚   â”‚   â”œâ”€â”€ hr/
â”‚   â”‚   â””â”€â”€ lr/
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ hr/
â”‚       â””â”€â”€ lr/
```

### 4. Configurar el Entrenamiento
Edita el archivo de configuraciÃ³n YAML en `options/train/EDSR/`:

```yaml
# ConfiguraciÃ³n general
name: EDSR_histopatologia_x2_f256_b32
model_type: SRModel
scale: 2
num_gpu: 1
manual_seed: 0

# Dataset configuration
datasets:
  train:
    name: histopatologia_train
    type: PairedImageDataset
    dataroot_gt: datasets/histopatologia/train/hr
    dataroot_lq: datasets/histopatologia/train/lr
    filename_tmpl: '{}'
    io_backend:
      type: disk
    
    gt_size: 256
    use_hflip: true
    use_rot: true
    
    # Data loader
    use_shuffle: true
    num_worker_per_gpu: 8
    batch_size_per_gpu: 4
    dataset_enlarge_ratio: 1
    prefetch_mode: ~

  val:
    name: histopatologia_val
    type: PairedImageDataset
    dataroot_gt: datasets/histopatologia/val/hr
    dataroot_lq: datasets/histopatologia/val/lr
    io_backend:
      type: disk

# Network structures
network_g:
  type: EDSR
  num_in_ch: 3
  num_out_ch: 3
  num_feat: 256           # NÃºmero de caracterÃ­sticas
  num_block: 32           # NÃºmero de bloques residuales
  upscale: 2
  res_scale: 0.1
  img_range: 255.
  rgb_mean: [0.4488, 0.4371, 0.4040]

# Training settings
train:
  ema_decay: 0.999
  optim_g:
    type: Adam
    lr: !!float 1e-4
    weight_decay: 0
    betas: [0.9, 0.99]

  scheduler:
    type: MultiStepLR
    milestones: [200000, 400000, 600000, 800000]
    gamma: 0.5

  total_iter: 1000000
  warmup_iter: -1  # Sin warmup

  # Losses
  pixel_opt:
    type: L1Loss
    loss_weight: 1.0
    reduction: mean
```

### 5. Ejecutar Entrenamiento
```bash
# Entrenamiento bÃ¡sico
python basicsr/train.py -opt options/train/EDSR/train_EDSR_histopatologia_x2.yml

# Con logging detallado
python basicsr/train.py -opt options/train/EDSR/train_EDSR_histopatologia_x2.yml --debug
```

## ğŸ“ **Estructura del Proyecto**

```
EDSR_BasicSR/
â”œâ”€â”€ basicsr/                        # Framework BasicSR
â”‚   â”œâ”€â”€ archs/                      # Arquitecturas de redes
â”‚   â”‚   â”œâ”€â”€ edsr_arch.py           # ImplementaciÃ³n EDSR
â”‚   â”‚   â””â”€â”€ arch_util.py           # Utilidades de arquitectura
â”‚   â”œâ”€â”€ data/                       # Manejo de datasets
â”‚   â”‚   â”œâ”€â”€ paired_image_dataset.py # Dataset pareado LR-HR
â”‚   â”‚   â””â”€â”€ transforms.py          # Transformaciones de datos
â”‚   â”œâ”€â”€ models/                     # Modelos de entrenamiento
â”‚   â”‚   â”œâ”€â”€ sr_model.py            # Modelo base de super-resoluciÃ³n
â”‚   â”‚   â””â”€â”€ base_model.py          # Modelo base
â”‚   â”œâ”€â”€ losses/                     # Funciones de pÃ©rdida
â”‚   â”‚   â”œâ”€â”€ basic_loss.py          # L1, L2, etc.
â”‚   â”‚   â””â”€â”€ perceptual_loss.py     # PÃ©rdida perceptual
â”‚   â””â”€â”€ train.py                   # Script principal de entrenamiento
â”œâ”€â”€ options/                        # Archivos de configuraciÃ³n
â”‚   â”œâ”€â”€ train/EDSR/                # Configuraciones de entrenamiento
â”‚   â”‚   â”œâ”€â”€ train_EDSR_histopatologia_x2.yml
â”‚   â”‚   â”œâ”€â”€ train_EDSR_histopatologia_x4.yml
â”‚   â”‚   â””â”€â”€ train_EDSR_custom.yml
â”‚   â””â”€â”€ test/EDSR/                 # Configuraciones de testing
â”œâ”€â”€ experiments/                    # Resultados experimentales
â”‚   â””â”€â”€ [experiment_name]/
â”‚       â”œâ”€â”€ models/                # Checkpoints del modelo
â”‚       â”œâ”€â”€ training_states/       # Estados del optimizador
â”‚       â”œâ”€â”€ visualization/         # ImÃ¡genes de validaciÃ³n
â”‚       â””â”€â”€ train_[timestamp].log  # Logs de entrenamiento
â”œâ”€â”€ datasets/                       # Datasets organizados
â”œâ”€â”€ results/                        # Resultados de testing
â””â”€â”€ requirements.txt               # Dependencias
```

## ğŸ§  **Arquitectura EDSR**

### **Enhanced Deep Super-Resolution Network**

EDSR elimina las capas de normalizaciÃ³n batch de ResNet original y utiliza:

```python
# Arquitectura base en basicsr/archs/edsr_arch.py
class EDSR(nn.Module):
    def __init__(self, num_in_ch=3, num_out_ch=3, num_feat=256, 
                 num_block=32, upscale=2, res_scale=0.1, img_range=255.):
        
        # ExtracciÃ³n de caracterÃ­sticas inicial
        self.conv_first = nn.Conv2d(num_in_ch, num_feat, 3, 1, 1)
        
        # Bloques residuales principales
        self.body = make_layer(ResidualBlockNoBN, num_block, 
                              num_feat=num_feat, res_scale=res_scale)
        
        # ConvoluciÃ³n antes del upsampling
        self.conv_after_body = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        
        # Upsampling
        self.upsample = Upsample(upscale, num_feat)
        
        # ReconstrucciÃ³n final
        self.conv_last = nn.Conv2d(num_feat, num_out_ch, 3, 1, 1)
```

### **Configuraciones por ResoluciÃ³n**

#### **128â†’256 (Ã—2) - ConfiguraciÃ³n EstÃ¡ndar**
```yaml
network_g:
  type: EDSR
  num_feat: 256
  num_block: 32
  upscale: 2
  res_scale: 0.1

train:
  total_iter: 300000
  batch_size_per_gpu: 16
```

#### **256â†’512 (Ã—2) - ConfiguraciÃ³n Intermedia**
```yaml
network_g:
  type: EDSR
  num_feat: 256
  num_block: 32
  upscale: 2
  res_scale: 0.1

train:
  total_iter: 500000
  batch_size_per_gpu: 8
```

#### **512â†’1024 (Ã—2) - Alta ResoluciÃ³n**
```yaml
network_g:
  type: EDSR
  num_feat: 256
  num_block: 32
  upscale: 2
  res_scale: 0.1

train:
  total_iter: 800000
  batch_size_per_gpu: 4
```

## ğŸš€ **Scripts Principales**

### **1. Entrenamiento**

#### Entrenamiento BÃ¡sico
```bash
python basicsr/train.py -opt options/train/EDSR/train_EDSR_histopatologia_x2.yml
```

#### Entrenamiento con ValidaciÃ³n AutomÃ¡tica
```bash
python basicsr/train.py \
    -opt options/train/EDSR/train_EDSR_histopatologia_x2.yml \
    --auto_resume \
    --debug
```

#### Reanudar Entrenamiento
```bash
python basicsr/train.py \
    -opt options/train/EDSR/train_EDSR_histopatologia_x2.yml \
    --auto_resume
```

### **2. Testing y EvaluaciÃ³n**

#### Testing BÃ¡sico
```bash
python basicsr/test.py -opt options/test/EDSR/test_EDSR_histopatologia_x2.yml
```

#### ConfiguraciÃ³n de Testing
```yaml
# test_EDSR_histopatologia_x2.yml
name: EDSR_histopatologia_x2_test
model_type: SRModel
scale: 2
num_gpu: 1

datasets:
  test_1:
    name: histopatologia_test
    type: PairedImageDataset
    dataroot_gt: datasets/histopatologia/test/hr
    dataroot_lq: datasets/histopatologia/test/lr
    io_backend:
      type: disk

network_g:
  type: EDSR
  num_in_ch: 3
  num_out_ch: 3
  num_feat: 256
  num_block: 32
  upscale: 2
  res_scale: 0.1
  img_range: 255.

path:
  pretrain_network_g: experiments/EDSR_histopatologia_x2/models/net_g_latest.pth
  strict_load_g: true

val:
  save_img: true
  suffix: ~  # Sin sufijo en nombre de archivo
  
  metrics:
    psnr: # Peak signal-to-noise ratio
      type: calculate_psnr
      crop_border: 2
      test_y_channel: false
      
    ssim: # Structural similarity
      type: calculate_ssim
      crop_border: 2
      test_y_channel: false
```

## âš™ï¸ **ConfiguraciÃ³n Avanzada**

### **OptimizaciÃ³n de Memoria**

Para GPUs con memoria limitada:

```yaml
# Reducir batch size
train:
  batch_size_per_gpu: 2  # En lugar de 4 o mÃ¡s

# Usar gradient checkpointing (si estÃ¡ disponible)
network_g:
  type: EDSR
  use_checkpoint: true  # Para ahorrar memoria

# Ajustar workers
datasets:
  train:
    num_worker_per_gpu: 4  # Reducir si hay problemas de memoria
```

### **AceleraciÃ³n de Entrenamiento**

```yaml
# Usar precisiÃ³n mixta (AMP)
train:
  use_amp: true
  
# Optimizar DataLoader
datasets:
  train:
    prefetch_mode: cuda  # Precarga en GPU
    pin_memory: true
    
# Scheduler optimizado
train:
  scheduler:
    type: CosineAnnealingRestartLR
    periods: [250000, 250000, 250000, 250000]
    restart_weights: [1, 0.5, 0.5, 0.5]
    eta_min: !!float 1e-7
```

### **Data Augmentation para HistopatologÃ­a**

```yaml
datasets:
  train:
    # Augmentaciones bÃ¡sicas
    use_hflip: true      # Flip horizontal
    use_rot: true        # Rotaciones 90Â°
    
    # Augmentaciones de color (cuidadoso en histopatologÃ­a)
    color_jitter_prob: 0.1
    color_jitter_shift: 20
    
    # Cropping inteligente
    gt_size: 256
    crop_type: center    # center, random
    
    # NormalizaciÃ³n especÃ­fica para histopatologÃ­a
    mean: [0.485, 0.456, 0.406]  # Valores tÃ­picos
    std: [0.229, 0.224, 0.225]
```

## ğŸ“Š **Resultados y Rendimiento**

### **Modelos Implementados**

| Modelo | ResoluciÃ³n | ParÃ¡metros | Tiempo Entrenamiento* | Estabilidad |
|--------|------------|------------|----------------------|-------------|
| 128â†’256 | 128Ã—128 â†’ 256Ã—256 | ~43M | ~2 dÃ­as | âœ… Excelente |
| 256â†’512 | 256Ã—256 â†’ 512Ã—512 | ~43M | ~3 dÃ­as | âœ… Excelente |
| 512â†’1024 | 512Ã—512 â†’ 1024Ã—1024 | ~43M | ~4 dÃ­as | âœ… Excelente |

*Tiempo estimado en RTX 4090

### **CaracterÃ­sticas TÃ©cnicas**

#### **Ventajas de EDSR:**
âœ… **Arquitectura probada**: CNN residual consolidada y estable  
âœ… **Entrenamiento robusto**: Sin problemas de convergencia  
âœ… **ImplementaciÃ³n limpia**: CÃ³digo bien estructurado y mantenible  
âœ… **Reproducibilidad**: Resultados consistentes entre ejecuciones  
âœ… **Escalabilidad**: Mantiene arquitectura constante entre resoluciones  
âœ… **Simplicidad**: Sin componentes adversariales complejos  

#### **CaracterÃ­sticas TÃ©cnicas:**
ğŸ”§ **FunciÃ³n de pÃ©rdida**: L1 Loss Ãºnicamente  
ğŸ”§ **Optimizador**: Adam con learning rate scheduling  
ğŸ”§ **NormalizaciÃ³n**: Sin Batch Normalization (clave del diseÃ±o)  
ğŸ”§ **ActivaciÃ³n**: ReLU en bloques residuales  
ğŸ”§ **Upsampling**: Sub-pixel convolution (PixelShuffle)  

### **ComparaciÃ³n de Estabilidad**

| Aspecto | EDSR | ESRGAN | SwinIR |
|---------|------|--------|--------|
| **Convergencia** | âœ… MonÃ³tona | âš ï¸ Oscilante | âœ… Estable |
| **Tiempo entrenamiento** | âš ï¸ Largo | âœ… Moderado | âš ï¸ Largo |
| **Reproducibilidad** | âœ… Excelente | âš ï¸ Variable | âœ… Buena |
| **Simplicidad** | âœ… MÃ¡xima | âš ï¸ Compleja | âš ï¸ Compleja |

## ğŸ”§ **Herramientas y Utilidades**

### **Monitoreo de Entrenamiento**

```bash
# Visualizar logs
tensorboard --logdir experiments/EDSR_histopatologia_x2/tb_logger

# MÃ©tricas automÃ¡ticas disponibles:
# - l_pix: PÃ©rdida L1
# - psnr: PSNR en validaciÃ³n
# - ssim: SSIM en validaciÃ³n
# - lr: Learning rate actual
```

### **GestiÃ³n de Experimentos**

```yaml
# ConfiguraciÃ³n de logging
logger:
  print_freq: 100           # Frecuencia de logs en consola
  save_checkpoint_freq: 5000 # Guardar modelo cada 5k iter
  use_tb_logger: true       # TensorBoard logging
  wandb:                    # Weights & Biases (opcional)
    project: EDSR_histopatologia
    resume_id: ~
```

### **ValidaciÃ³n AutomÃ¡tica**

```yaml
# ValidaciÃ³n durante entrenamiento
val:
  val_freq: !!float 5e3    # Validar cada 5k iteraciones
  save_img: false          # No guardar imÃ¡genes (ahorra espacio)
  
  metrics:
    psnr:
      type: calculate_psnr
      crop_border: 2
      test_y_channel: false
    ssim:
      type: calculate_ssim
      crop_border: 2
      test_y_channel: false
```

## ğŸ—ï¸ **PersonalizaciÃ³n y Extensiones**

### **Modificar Arquitectura**

```python
# En basicsr/archs/edsr_arch.py
class CustomEDSR(nn.Module):
    def __init__(self, num_in_ch=3, num_out_ch=3, num_feat=256, 
                 num_block=32, upscale=2, res_scale=0.1):
        
        # Modificar nÃºmero de caracterÃ­sticas
        self.conv_first = nn.Conv2d(num_in_ch, num_feat, 3, 1, 1)
        
        # Ajustar nÃºmero de bloques residuales
        self.body = make_layer(ResidualBlockNoBN, num_block, 
                              num_feat=num_feat, res_scale=res_scale)
```

### **Funciones de PÃ©rdida Personalizadas**

```python
# En basicsr/losses/custom_loss.py
class HistopathologyLoss(nn.Module):
    def __init__(self, loss_weight=1.0):
        super().__init__()
        self.loss_weight = loss_weight
        self.l1_loss = nn.L1Loss()
        
    def forward(self, pred, target):
        # PÃ©rdida L1 base
        l1_loss = self.l1_loss(pred, target)
        
        # Agregar pÃ©rdidas especÃ­ficas para histopatologÃ­a
        # (preservaciÃ³n de bordes, texturas, etc.)
        
        return l1_loss * self.loss_weight
```

## ğŸ¯ **Casos de Uso y Aplicaciones**

### **DiagnÃ³stico MÃ©dico Asistido**
- Mejora de imÃ¡genes histopatolÃ³gicas de baja calidad
- PreparaciÃ³n de imÃ¡genes para anÃ¡lisis automatizado
- StandardizaciÃ³n de calidad en diferentes equipos de microscopÃ­a

### **InvestigaciÃ³n CientÃ­fica**
- Baseline confiable para comparaciones experimentales
- Arquitectura de referencia para nuevos mÃ©todos
- ValidaciÃ³n de tÃ©cnicas de evaluaciÃ³n

### **AnÃ¡lisis de Estructuras Celulares**
- PreservaciÃ³n fiel de morfologÃ­a tisular
- ReconstrucciÃ³n estable de patrones histolÃ³gicos
- AnÃ¡lisis detallado de arquitectura glandular

## ğŸ¤ **ContribuciÃ³n**

Este proyecto es parte de un Trabajo de Grado enfocado en super-resoluciÃ³n mÃ©dica. Las contribuciones son bienvenidas siguiendo las mejores prÃ¡cticas de BasicSR.

## ğŸ“„ **Licencia**

Este proyecto estÃ¡ licenciado bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

## ğŸ™ **Reconocimientos**

- **Framework Original**: [BasicSR](https://github.com/XPixelGroup/BasicSR) por XPixel Group
- **EDSR Paper**: Lim, Bee, et al. "Enhanced deep residual networks for single image super-resolution." CVPRW 2017.
- **ResNet**: He, Kaiming, et al. "Deep residual learning for image recognition." CVPR 2016.
- **BasicSR Team**: Por el excelente framework de super-resoluciÃ³n

## ğŸ“ **Contacto**

- **Autor**: Juan David Cruz Useche
- **Proyecto**: Trabajo de Grado - Super-ResoluciÃ³n para HistopatologÃ­a
- **GitHub**: [@JuanHoKKeR](https://github.com/JuanHoKKeR)
- **Repositorio**: [EDSR_BasicSR](https://github.com/JuanHoKKeR/EDSR_BasicSR)

## ğŸ“š **Referencias**

```bibtex
@inproceedings{lim2017enhanced,
  title={Enhanced deep residual networks for single image super-resolution},
  author={Lim, Bee and Son, Sanghyun and Kim, Heewon and Nah, Seungjun and Mu Lee, Kyoung},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition workshops},
  pages={136--144},
  year={2017}
}

@misc{wang2020basicsr,
  title={BasicSR: Open Source Image and Video Restoration Toolbox},
  author={Xintao Wang and Liangbin Xie and Chao Dong and Ying Shan},
  howpublished={\url{https://github.com/XPixelGroup/BasicSR}},
  year={2020}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
```

---

**â­ Si este proyecto te resulta Ãºtil para tu investigaciÃ³n en super-resoluciÃ³n mÃ©dica, considera darle una estrella!**